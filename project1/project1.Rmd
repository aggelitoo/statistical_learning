---
title: "Project 1 - Statistical learning"
author: "August Jonasson"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r, include=FALSE}
library(tidyverse)
library(quantmod)
library(corrplot)
library(glmnet)
library(magrittr)
```

## Task 1: Linear regression

Loading the stock data.
```{r, include=FALSE}
tickers = c("^OMX",
            "ABB.ST",
            "NDA-SE.ST",
            "HM-B.ST",
            "ATCO-A.ST",
            "ERIC-B.ST", 
            "ESSITY-B.ST",
            "SAND.ST",
            "BOL.ST",
            "GETI-B.ST",
            "ALFA.ST",
            "ATCO-B.ST",
            "VOLV-B.ST",
            "SHB-A.ST",
            "ELUX-B.ST", 
            "SEB-A.ST",
            "ASSA-B.ST",
            "AZN.ST",
            "SWED-A.ST",
            "TELIA.ST",
            "TEL2-B.ST",
            "SBB-B.ST",
            "INVE-B.ST",
            "SCA-B.ST",
            "HEXA-B.ST",
            "SINCH.ST")

getSymbols(tickers, src="yahoo", from = '2017-12-31', to = "2023-12-31")

# adjusting "bad" names
NDA_SE.ST = `NDA-SE.ST`
HM_B.ST = `HM-B.ST`
ATCO_A.ST = `ATCO-A.ST`
ERIC_B.ST = `ERIC-B.ST`
ESSITY_B.ST = `ESSITY-B.ST`
GETI_B.ST = `GETI-B.ST`
ATCO_B.ST = `ATCO-B.ST`
VOLV_B.ST = `VOLV-B.ST`
SHB_A.ST = `SHB-A.ST`
ELUX_B.ST = `ELUX-B.ST`
SEB_A.ST = `SEB-A.ST`
ASSA_B.ST = `ASSA-B.ST`
SWED_A.ST = `SWED-A.ST`
TEL2_B.ST = `TEL2-B.ST`
SBB_B.ST = `SBB-B.ST`
INVE_B.ST = `INVE-B.ST`
NDA_SE.ST = `NDA-SE.ST`
SCA_B.ST = `SCA-B.ST`
HEXA_B.ST = `HEXA-B.ST`

OMX_ad = OMX$OMX.Adjusted
ABB.ST_ad = ABB.ST$ABB.ST.Adjusted
NDA_SE.ST_ad = NDA_SE.ST$`NDA-SE.ST.Adjusted`
HM_B.ST_ad = HM_B.ST$`HM-B.ST.Adjusted`
ATCO_A.ST_ad = ATCO_A.ST$`ATCO-A.ST.Adjusted`
ERIC_B.ST_ad = ERIC_B.ST$`ERIC-B.ST.Adjusted`
ESSITY_B.ST_ad = ESSITY_B.ST$`ESSITY-B.ST.Adjusted`
SAND.ST_ad = SAND.ST$SAND.ST.Adjusted
BOL.ST_ad = BOL.ST$BOL.ST.Adjusted
GETI_B.ST_ad = GETI_B.ST$`GETI-B.ST.Adjusted`
ALFA.ST_ad = ALFA.ST$ALFA.ST.Adjusted
ATCO_B.ST_ad = ATCO_B.ST$`ATCO-B.ST.Adjusted`
VOLV_B.ST_ad = VOLV_B.ST$`VOLV-B.ST.Adjusted`
SHB_A.ST_ad = SHB_A.ST$`SHB-A.ST.Adjusted`
ELUX_B.ST_ad = ELUX_B.ST$`ELUX-B.ST.Adjusted`
SEB_A.ST_ad = SEB_A.ST$`SEB-A.ST.Adjusted`
ASSA_B.ST_ad = ASSA_B.ST$`ASSA-B.ST.Adjusted`
AZN.ST_ad = AZN.ST$AZN.ST.Adjusted
SWED_A.ST_ad = SWED_A.ST$`SWED-A.ST.Adjusted`
TELIA.ST_ad = TELIA.ST$TELIA.ST.Adjusted
TEL2_B.ST_ad = TEL2_B.ST$`TEL2-B.ST.Adjusted`
SBB_B.ST_ad = SBB_B.ST$`SBB-B.ST.Adjusted`
INVE_B.ST_ad = INVE_B.ST$`INVE-B.ST.Adjusted`
SINCH.ST_ad = SINCH.ST$SINCH.ST.Adjusted
SCA_B.ST_ad = SCA_B.ST$`SCA-B.ST.Adjusted`
HEXA_B.ST_ad = HEXA_B.ST$`HEXA-B.ST.Adjusted`

market_data=cbind(OMX_ad,ABB.ST_ad,NDA_SE.ST_ad, HM_B.ST_ad, ATCO_A.ST_ad,
                  ERIC_B.ST_ad, ESSITY_B.ST_ad, SAND.ST_ad, BOL.ST_ad,
                  GETI_B.ST_ad, ALFA.ST_ad, ATCO_B.ST_ad, VOLV_B.ST_ad,
                  SHB_A.ST_ad, ELUX_B.ST_ad, SEB_A.ST_ad, ASSA_B.ST_ad, 
                  AZN.ST_ad, SWED_A.ST_ad, TELIA.ST_ad, TEL2_B.ST_ad,
                  SBB_B.ST_ad, INVE_B.ST_ad, SINCH.ST_ad, SCA_B.ST_ad, 
                  HEXA_B.ST_ad)

k=nrow(market_data)
returns=as.data.frame(log(as.matrix(market_data[2:k,]))-log(
  as.matrix(market_data[1:(k-1),])))
names(returns)=c("rOMX","rABB","rNDA.SE.ST", "HM_B.ST", "ATCO_A.ST",
                 "ERIC_B.ST", "ESSITY_B.ST", "SAND.ST", "BOL.ST",
                 "GETI_B.ST", "ALFA.ST", "ATCO_B.ST", "VOLV_B.ST",
                 "SHB_A.ST", "ELUX_B.ST", "SEB_A.ST", "ASSA_B.ST",
                 "AZN.ST", "SWED_A.ST", "TELIA.ST", "TEL2_B.ST",
                 "SBB_B.ST", "INVE_B.ST", "SINCH.ST", "SCA_B.ST",
                 "HEXA_B.ST")

save(returns, file = "returns.Rda")
```


```{r, include=FALSE}
load("returns.Rda")
returns <- na.omit(returns)
```


### (a)
Fitting a linear regression model with the stock log-returns as predictors and
the log-return of the capital index as response.
```{r}
model <- lm(data = returns, rOMX ~ .)
summary(model)
```
According to the p-values of the above summary, none of the features are
insignificant in their ability to predict the log-returns on the capital market
index. This is not surprising at all, since we chose our predictors as the most
important stocks on the market. The capital market index is modeled after these
stocks. Also, the effects (coefficient estimates) of all features are very
similar, i.e. no particular one feature stands out as having more or less of an
impact.

By significance, we mean that under the null-hypothesis: that said coefficient
has no effect on the response while keeping the others constanst, the observed value would be less than 5 % likely
to occur (95 % significance level). For all of our coefficients, this
probability is well below 5 % and for most of them, this probability is more
or less zero.

### (b)
No, the results from part (a) cannot be used to answer the question of which of
the stocks have to be included in the mdoel in order to mimic the behavior of
the swedish capital market index. We have not adressed potential
contaminators such as multicolinearity, overfitting and joint significance 
between the predictors (we have only checked marginal significance). We have
also not validated our model in the sense that we have no idea how it will
perform on actual test data. 

### (c)
Now using the forward selection in order to select the model. This is done by
initially only using an intercept and the response variable, and then
iteratively adding whichever feature would yield the most significance until no
further improvement is seen.
```{r}
forward_model <- step(model, direction = "forward",
                      scope = formula(~ .))

summary(forward_model)
```


### (d)

```{r}
backward_model <- step(model, direction = "backward")
summary(backward_model)
```

The backward selection yields the same result as the forward selection.


### (e)

First, we want to fit the ridge regression model.
```{r}
x_var <- as.matrix(returns[,2:26])
y_var <- as.matrix(returns[,1])
ridge_fit <- glmnet(x_var, y_var, alpha = 0, lambda.min.ratio = 1e-6)
```
Next, in order to choose the best $\lambda$ we will use leave-one-out
cross-validation.

```{r, cache=TRUE}
# cross-validation
ridge_cv <- cv.glmnet(x_var, y_var, alpha = 0)
```


```{r}
# printing the best lambda for ridge
ridge_best_lambda <- ridge_cv$lambda.min
print(ridge_best_lambda)
```
We can now print the coefficient estimates against the tested values on
$\lambda$. We also include a red, dashed vertical line that indicates the
optimal value on $\lambda$ found by the cross-validation. As can be seen from
the resulting plot, the $\lambda$ that we found results in next to no shrinkage
at all.

```{r}
plot(ridge_fit, xvar = "lambda")
abline(v = log(ridge_best_lambda), lty = "dashed", col = "red")
```

Fitting a new ridge model using this best $\lambda$ we can compare the
coefficient estimates to the simple linear regression model from the first task
and see that they are more or less identical.
```{r}
best_ridge_fit <- glmnet(x_var, y_var, alpha = 0, lambda = ridge_best_lambda)
best_ridge_fit$beta
```



### (f)
Using the Lasso regression and performing the same steps as in the ridge
regression task.

```{r}
# fitting the model
lasso_fit <- glmnet(x_var, y_var, alpha = 1, lambda.min.ratio = 1e-6)

# cross-validation to get best lambda
lasso_cv <- cv.glmnet(x_var, y_var, alpha = 1)

# printing the best lambda for lasso 
lasso_best_lambda <- lasso_cv$lambda.min
print(lasso_best_lambda)
```


```{r}
plot(lasso_fit, xvar = "lambda")
abline(v = log(lasso_best_lambda), lty = "dashed", col = "red")
```

Again, let us examine the coefficients of the model that uses this best lambda
for the lasso regression. Again, we can see that next to no shrinkage at all has
been applied.

```{r}
best_lasso_fit <- glmnet(x_var, y_var, alpha = 1, lambda = lasso_best_lambda)
best_lasso_fit$beta
```

### (g)

According to the results from all of the previous tasks, we can (a bit naively)
deduce that all stocks should be included in order to mimic the Swedish capital
market index. This is naive in the sense that we have not examined potential
co-linearity in any of the steps. Maybe even more importantly, many of the
coefficient estimates are very small. Is the added complexity of the model
really worth coefficients with such small effects? Probably not.

## Task 2: Linear classification

### (a)
We start by splitting the data into 80/20 (preserving chronology) and also
convert our response variable to binary categorical such that if the return on 
capital market index on day $t$ is positive we assign $1$, and $0$ otherwise.
```{r}
# converting capital market index variable to binary categorical
returns_cat <- returns %>%
  mutate(rOMX = ifelse(rOMX > 0, 1, 0))

# length of data in order make split
n_data <- nrow(returns_cat)

# creating integer representing roughly 80 % split of data.
training_length <- round(n_data * 0.8)

# splitting the data into training and test
train_data <- returns_cat[1:training_length, ]
test_data <- returns_cat[(training_length+1):n_data, ]
```

Since the purpose of this task is to train two different models - one using all
of the 25 stocks as predictors and the other only using the subset of stocks 
selected by the lasso regression in the previous task - but our lasso also
selected all of the stocks as the best model, we decide to arbitrarily remove
half of the coefficients for the second model. We remove the half which has the
lowest coefficient estimates, as these should affect the model the least. 

```{r}
# selecting the 12 stocks which coeff estimates were the highest in the lin mod
subset_stocks <- model$coefficients %>%
  data.frame() %>%
  set_colnames("coeff") %>%
  arrange(desc(coeff)) %>%
  t()

subset_stocks <- colnames(subset_stocks)[1:12]
```

```{r}
# the dimensions of the resulting data sets
dim(train_data)
dim(test_data)
```

```{r}
# all stocks model
logmodel_full <- glm(rOMX ~ ., family = binomial, data = train_data)

# stock subset model
logmodel_subset <- glm(rOMX ~ ., family = binomial,
                    data = train_data[c("rOMX", subset_stocks)])
```

```{r}
summary(logmodel_full)
```

```{r}
summary(logmodel_subset)
```

### (b)
```{r}
# predictions of the full model
predictions_full <- predict(logmodel_full,
                       newdata = select(test_data, !rOMX),
                       type = "response")
pred_labels_full <- ifelse(predictions_full > 0.5, 1, 0)

# predictions of the subset model
predictions_subset <- predict(logmodel_subset,
                       newdata = test_data[subset_stocks],
                       type = "response")
pred_labels_subset <- ifelse(predictions_subset > 0.5, 1, 0)
```


And now checking the prediction accuracy.
```{r}
n_test_data <- nrow(test_data)
true_labels <- test_data["rOMX"]

full_model_misclassifications <- abs(true_labels - pred_labels_full) %>% sum()
sub_model_misclassifications <- abs(true_labels - pred_labels_subset) %>% sum()

full_model_accuracy <- full_model_misclassifications / n_test_data
sub_model_accuracy <- sub_model_misclassifications / n_test_data

full_model_accuracy
sub_model_accuracy
```

### (c)

